{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Distortion Correction Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the original images and corrected images\n",
    "\n",
    "for imgName in images:\n",
    "    img = cv2.imread(imgName)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    undistorted = cv2.undistort(gray, mtx, dist, None, mtx)\n",
    "    tmp = np.vstack((gray, undistorted))\n",
    "    cv2.imshow('img', tmp)\n",
    "    cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## gradient && threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## different kinds of gradient and threshold\n",
    "def xDirGradThreshold(img, sobel_kernel=3, thresh = (0,255)):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    binary_output = np.zeros_like(sobelx)\n",
    "    binary_output[(sobelx >= thresh[0])& (sobelx <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "    \n",
    "def yDirGradThreshold(img, sobel_kernel=3, thresh = (0,255)):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    binary_output = np.zeros_like(sobely)\n",
    "    binary_output[(sobely >= thresh[0])&(sobely <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def magGradThreshold(img, sobel_kernel=3, thresh = (0,255)):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    sobelMag = np.sqrt(np.square(sobelx) + np.square(sobely))\n",
    "    scaled_sobelMag = np.uint8(255*sobelMag/np.max(sobelMag))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobelMag)\n",
    "    binary_output[(scaled_sobelMag > thresh[0])&(scaled_sobelMag < thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def dirGradThreshold(img, sobel_kernel=3, thresh=(0,np.pi/2)):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    dirGrd = np.arctan2(abs_sobely, abs_sobelx)\n",
    "\n",
    "    binary_output = np.zeros_like(dirGrd)\n",
    "    binary_output[(dirGrd >= thresh[0])&(dirGrd <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def hlsGradThreshold(img, sobel_kernel=3, thresh=(0,10)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    L = hls[:,:,1]\n",
    "    S = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def absoluteGradThreshold(img, orientation='x', sobel_kernel=3, thresh=(0,255)):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "    else:\n",
    "        return 'wrong direction'\n",
    "\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel) \n",
    "    binary_output[(scaled_sobel > thresh[0]) & (scaled_sobel < thresh_max[1])] = 1\n",
    "    return binary_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "# test on stright line images \n",
    "test_images = glob.glob('./test_images/*.jpg')\n",
    "img_SL = cv2.imread(test_images[0])\n",
    "print (img_SL.shape)\n",
    "cv2.imshow('straight line', img_SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#combination of gradient thresh\n",
    "def combinationGD(img):\n",
    "    \n",
    "    binary_mag = magGradThreshold(img, 5, (50,100))\n",
    "    binary_hls = hlsGradThreshold(img, 5, (100,255))\n",
    "    binary_dir = dirGradThreshold(img, 5, (np.pi/2,1.7))\n",
    "    binary_comb = np.zeros_like(binary_mag)\n",
    "    binary_comb[((binary_mag==1) & (binary_dir==1))|(binary_hls==1)] = 1\n",
    "    \n",
    "    return binary_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1c32680cc0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perspective transf\n",
    "nx = 1280\n",
    "ny = 720\n",
    "\n",
    "img = cv2.imread(test_images[5])\n",
    "undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "binaryComb = combinationGD(undistorted)\n",
    "plt.subplot(211)\n",
    "# plt.imshow(binaryComb, cmap='gray')\n",
    "plt.imshow(undistorted)\n",
    "\n",
    "src = np.float32([[595,440],[685,440],[1200,690],[80,690]])\n",
    "dst = np.float32([[0,0],[nx,0],[nx, ny],[0,ny]])\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "warped = cv2.warpPerspective(binaryComb, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "plt.subplot(212)\n",
    "plt.imshow(warped, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#sliding windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#whole process of lane detection\n",
    "# \n",
    "# Step 1: distortion correction;\n",
    "# Step 2: color&gradient threshold;\n",
    "# Step 3: perspective transform;\n",
    "# Step 4: sliding windows\n",
    "# Step 5: return to image\n",
    "def adLaneDetect(img):\n",
    "    #step1\n",
    "    undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    #step2\n",
    "    binaryComb = combinationGD(undistorted)\n",
    "    #step3\n",
    "    warped = cv2.warpPerspective(binaryComb, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'white2.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
